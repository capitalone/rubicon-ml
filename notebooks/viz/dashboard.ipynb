{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "061ee14e-0fab-4eaf-93db-b445b743174c",
   "metadata": {},
   "source": [
    "# Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5be9ae89-279f-4c3c-87e8-ab5ff2de34c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from rubicon_ml import Rubicon\n",
    "from rubicon_ml.viz import DataframePlot, ExperimentsTable, MetricCorrelationPlot, MetricListsComparison\n",
    "from rubicon_ml.viz.dashboard import Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "039b59fc-709d-48a8-88de-0c97f9966dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(start=\"1/1/2010\", end=\"12/1/2020\", freq=\"MS\")\n",
    "\n",
    "rubicon = Rubicon(persistence=\"memory\", auto_git_enabled=True)\n",
    "project = rubicon.get_or_create_project(\"dashboard composition\")\n",
    "\n",
    "for i in range(0, 10):\n",
    "    experiment = project.log_experiment()\n",
    "\n",
    "    experiment.log_parameter(name=\"is_standardized\", value=random.choice([True, False]))\n",
    "    experiment.log_parameter(name=\"n_estimators\", value=random.randrange(2, 10, 2))\n",
    "    experiment.log_parameter(name=\"sample\", value=random.choice([\"A\", \"B\", \"C\", \"D\", \"E\"]))\n",
    "\n",
    "    experiment.log_metric(name=\"accuracy\", value=random.random())\n",
    "    experiment.log_metric(name=\"confidence\", value=random.random())\n",
    "\n",
    "    experiment.log_metric(name=\"coefficients\", value=[random.random() for _ in range(0, 5)])\n",
    "    experiment.log_metric(name=\"stderr\", value=[random.random() for _ in range(0, 5)])\n",
    "\n",
    "    data = np.array([list(dates), np.linspace(random.randint(0, 15000), random.randint(0, 15000), len(dates))])\n",
    "    data_df = pd.DataFrame.from_records(data.T, columns=[\"calendar month\", \"open accounts\"])\n",
    "\n",
    "    experiment.log_dataframe(data_df, name=\"open accounts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03945010-f8fa-4d01-9f03-94b52586f8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8058/\n",
      "\n",
      " * Serving Flask app 'rubicon_ml.viz.base' (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    }
   ],
   "source": [
    "default_dashbaord = Dashboard(experiments=project.experiments())\n",
    "default_dashbaord.serve(run_server_kwargs={\"port\": 8058})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46575d2-509f-4c8f-8ccb-1f9043e71627",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dashboard(\n",
    "    experiments=project.experiments(),\n",
    "    widgets=[\n",
    "        [\n",
    "            ExperimentsTable(is_selectable=True),\n",
    "            MetricCorrelationPlot(selected_metric=\"accuracy\"),\n",
    "        ],\n",
    "        [\n",
    "            \n",
    "            MetricListsComparison(column_names=[f\"var_00{i}\" for i in range(0, 5)]),\n",
    "            DataframePlot(dataframe_name=\"open accounts\"),\n",
    "        ],\n",
    "    ],\n",
    ").serve()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
