{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffc55deb-dc28-4d36-be12-c375ca24e5d3",
   "metadata": {},
   "source": [
    "# Logging Experiments\n",
    "\n",
    "``rubicon_ml``'s core functionality is centered around logging **experiments** to explain and explore various\n",
    "model runs throughout the model development lifecycle. This example will take a quick look at how we can log\n",
    "model metadata to ``rubicon_ml`` in the context of a simple classification project.\n",
    "\n",
    "We'll leverage the ``palmerpenguins`` dataset collected by Dr. Kristen Gorman as our training/testing data. More\n",
    "information on the dataset can be found here:\n",
    "> https://allisonhorst.github.io/palmerpenguins/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934210f6-3701-47bb-9223-bd18171ea761",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install palmerpenguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d58148e-69af-4664-8cf5-328a884943ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from palmerpenguins import load_penguins\n",
    "\n",
    "penguins_df = load_penguins()\n",
    "target_values = penguins_df['species'].unique()\n",
    "\n",
    "print(f\"target classes (species): {target_values}\")\n",
    "penguins_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e515256-72ae-4a27-9f5f-03a5313d6b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "for column in [\"species\", \"island\", \"sex\"]:\n",
    "    penguins_df[column] = LabelEncoder().fit_transform(penguins_df[column])\n",
    "\n",
    "print(f\"target classes (species): {penguins_df['species'].unique()}\")\n",
    "penguins_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab60bf-29db-4cb3-89ec-fba1f6f7c23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_penguins_df, test_penguins_df = train_test_split(penguins_df, test_size=.30)\n",
    "\n",
    "target_name = \"species\"\n",
    "feature_names = [c for c in train_penguins_df.columns if c != target_name]\n",
    "\n",
    "X_train, y_train = train_penguins_df[feature_names], train_penguins_df[target_name]\n",
    "X_test, y_test = test_penguins_df[feature_names], test_penguins_df[target_name]\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bb797b-1757-4319-876c-41cd2156237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "imputer_strategy = \"mean\"\n",
    "classifier_n_neighbors = 5\n",
    "\n",
    "steps = [\n",
    "    (\"si\", SimpleImputer(strategy=imputer_strategy)),\n",
    "    (\"kn\", KNeighborsClassifier(n_neighbors=classifier_n_neighbors)),\n",
    "]\n",
    "\n",
    "penguin_pipeline = Pipeline(steps=steps)\n",
    "penguin_pipeline.fit(X_train, y_train)\n",
    "\n",
    "score = penguin_pipeline.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d234a1d-d143-4ad8-80ce-512fbc8327f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rubicon_ml import Rubicon\n",
    "\n",
    "rubicon = Rubicon(\n",
    "    persistence=\"filesystem\",\n",
    "    root_dir=\"./rubicon-root\",\n",
    "    auto_git_enabled=True,\n",
    ")\n",
    "project = rubicon.get_or_create_project(name=\"classifying penguins\")\n",
    "experiment = project.log_experiment()\n",
    "\n",
    "for feature_name in feature_names:\n",
    "    experiment.log_feature(name=feature_name)\n",
    "\n",
    "experiment.log_parameter(name=\"strategy\", value=imputer_strategy)\n",
    "experiment.log_parameter(name=\"n_neighbors\", value=classifier_n_neighbors)\n",
    "experiment.log_metric(name=\"accuracy\", value=score)\n",
    "\n",
    "print(experiment)\n",
    "print()\n",
    "print(f\"git info:\")\n",
    "print(f\"\\tbranch name: {experiment.branch_name}\\n\\tcommit hash: {experiment.commit_hash}\")\n",
    "print(f\"features: {[f.name for f in experiment.features()]}\")\n",
    "print(f\"parameters: {[(p.name, p.value) for p in experiment.parameters()]}\")\n",
    "print(f\"metrics: {[(m.name, m.value) for m in experiment.metrics()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe5fa9-3ff7-4ab9-8213-bfd1199e0520",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "for imputer_strategy in [\"mean\", \"median\", \"most_frequent\"]:\n",
    "    for classifier_n_neighbors in [5, 10, 15, 20]:\n",
    "        pipeline = clone(penguin_pipeline)\n",
    "        pipeline.set_params(\n",
    "            si__strategy=imputer_strategy,\n",
    "            kn__n_neighbors=classifier_n_neighbors,\n",
    "        )\n",
    "        \n",
    "        pipeline.fit(X_train, y_train)\n",
    "        score = pipeline.score(X_test, y_test)\n",
    "\n",
    "        experiment = project.log_experiment(tags=[\"parameter search\"])\n",
    "\n",
    "        for feature_name in feature_names:\n",
    "            experiment.log_feature(name=feature_name)\n",
    "        experiment.log_parameter(name=\"strategy\", value=imputer_strategy)\n",
    "        experiment.log_parameter(name=\"n_neighbors\", value=classifier_n_neighbors)\n",
    "        experiment.log_metric(name=\"accuracy\", value=score)\n",
    "\n",
    "print(\"experiments:\")\n",
    "for experiment in project.experiments(tags=[\"parameter search\"]):\n",
    "    print(\n",
    "        f\"\\tid: {experiment.id}, \"\n",
    "        f\"parameters: {[(p.name, p.value) for p in experiment.parameters()]}, \"\n",
    "        f\"metrics: {[(m.name, m.value) for m in experiment.metrics()]}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2240e03d-b8a6-4c40-a570-512873ff7277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "experiment = project.experiments(tags=[\"parameter search\"])[-1]\n",
    "\n",
    "trained_model = pipeline._final_estimator\n",
    "experiment.log_artifact(data_bytes=pickle.dumps(trained_model), name=\"trained model\")\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "confusion_matrix_df = pd.DataFrame(\n",
    "    confusion_matrix(y_test, y_pred),\n",
    "    columns=target_values,\n",
    "    index=target_values,\n",
    ")\n",
    "experiment.log_dataframe(confusion_matrix_df, name=\"confusion matrix\")\n",
    "\n",
    "print(pickle.loads(experiment.artifact(name=\"trained model\").data))\n",
    "experiment.dataframe(name=\"confusion matrix\").data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
