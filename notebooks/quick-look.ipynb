{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Look\n",
    "\n",
    "This is a simple classification example based on\n",
    "[this Scikit-learn example](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html#sphx-glr-auto-examples-preprocessing-plot-scaling-importance-py).\n",
    "The wine dataset used in this example classifies different Italian wines by the cultivators that produced them\n",
    "based on 13 features describing their chemical makeup. More infomation on this dataset can be found by running \n",
    "``print(wine.DESCR)`` after the dataset has been loaded.\n",
    "\n",
    "We'll use this example to take a quick look at each of ``rubicon_ml``'s core components - logging, the dashboard, and\n",
    "our sharing process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    wine.data,\n",
    "    wine.target,\n",
    "    test_size=0.50,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logging Library\n",
    "\n",
    "The logging library provides an API for storing and retrieving model inputs, outputs, and analyses. Using ``fsspec``,\n",
    "it supports three types of persistence:\n",
    "\n",
    "* **local**: for personal projects and individual exploration\n",
    "* **S3**: for collaborating, sharing, and backing up local work\n",
    "* **in-memory**: for testing and development - no need to clean up after yourself!\n",
    "\n",
    "Within ``rubicon_ml``, the implementations of these filesystems are very lightweight, with most functionality coming\n",
    "directly from ``fsspec``. In fact, ``rubicon_ml``’s persistence layer is designed to be easily extensible and could\n",
    "be extended to support any other type of persistence that ``fsspec`` supports.\n",
    "\n",
    "### Local Logging\n",
    "\n",
    "First, we'll configure our ``Rubicon`` object and create a project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rubicon_ml.client.project.Project at 0x15ac30370>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from rubicon_ml import Rubicon\n",
    "\n",
    "\n",
    "root_dir = os.environ.get(\"RUBICON_ROOT\", \"rubicon-root\")\n",
    "root_path = f\"{os.getcwd()}/{root_dir}\"\n",
    "\n",
    "rubicon = Rubicon(persistence=\"filesystem\", root_dir=root_path)\n",
    "project = rubicon.get_or_create_project(\"Wine Classification\")\n",
    "\n",
    "project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll also create a ``run_experiment`` function to abstract our logging into a single spot. This\n",
    "isn't necessary - ``rubicon_ml`` is designed to be flexible and fit into your workflow however you see fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def run_experiment(project, is_standardized=False, n_components=2):\n",
    "    experiment = project.log_experiment(model_name=GaussianNB.__name__)\n",
    "    \n",
    "    experiment.log_parameter(\"is_standardized\", is_standardized)\n",
    "    experiment.log_parameter(\"n_components\", n_components)\n",
    "\n",
    "    for name in wine.feature_names:\n",
    "        experiment.log_feature(name)\n",
    "\n",
    "    if is_standardized:\n",
    "        classifier = make_pipeline(\n",
    "            StandardScaler(),\n",
    "            PCA(n_components=n_components),\n",
    "            GaussianNB(),\n",
    "        )\n",
    "    else:\n",
    "        classifier = make_pipeline(\n",
    "            PCA(n_components=n_components),\n",
    "            GaussianNB(),\n",
    "        )\n",
    "        \n",
    "    classifier.fit(X_train, y_train)\n",
    "    pred_test = classifier.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, pred_test)\n",
    "    \n",
    "    experiment.log_metric(\"accuracy\", accuracy)\n",
    "    \n",
    "    confusion_matrix = pd.crosstab(\n",
    "        wine.target_names[y_test],\n",
    "        wine.target_names[pred_test],\n",
    "        rownames=[\"actual\"],\n",
    "        colnames=[\"predicted\"],\n",
    "    )\n",
    "    \n",
    "    experiment.log_dataframe(\n",
    "        confusion_matrix,\n",
    "        tags=[\"confusion matrix\"],\n",
    "    )\n",
    "\n",
    "    if accuracy >= .9:\n",
    "        experiment.add_tags([\"success\"])\n",
    "    else:\n",
    "        experiment.add_tags([\"failure\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run our experiment across a few different parameter sets! We'll end up with 14\n",
    "unique experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for is_standardized in [True, False]:\n",
    "    for n_components in range(1, 15, 2):\n",
    "        run_experiment(\n",
    "            project,\n",
    "            is_standardized=is_standardized,\n",
    "            n_components=n_components,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S3 Logging\n",
    "\n",
    "Logging to S3 is as simple as changing the ``root_dir`` when instantiating the ``Rubicon`` object:\n",
    "\n",
    "```python\n",
    "rubicon = Rubicon(\n",
    "    persistence=\"filesystem\",\n",
    "    root_dir=\"s3://my-bucket/path/to/rubicon-root\",\n",
    ")\n",
    "```\n",
    "\n",
    "### In-memory Logging\n",
    "\n",
    "The same is true of in-memory logging! In-memory logging doesn't require a ``root_dir``, but if\n",
    "you're working with other in-memory ``fsspec`` filesystems you can still provide one.\n",
    "\n",
    "```python\n",
    "rubicon = Rubicon(persistence=\"memory\")\n",
    "```\n",
    "\n",
    "## Dashboard\n",
    "\n",
    "``rubicon_ml`` comes with a UI add-on (installable as rubicon-ml[ui] if you're using ``pip`` to manage\n",
    "your Python environment) that allows you to explore, visualize, and compare data within your\n",
    "projects. If you have ``git`` integration enabled, the dashboard will group your\n",
    "experiments by commit automatically and link you directly to the corresponding model code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [12/May/2021 09:58:14] \"\u001b[37mGET /_alive_10a36bff-b1c3-4f41-951e-b57ddc890f93 HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8050/\n"
     ]
    }
   ],
   "source": [
    "from rubicon_ml.ui import Dashboard\n",
    "\n",
    "\n",
    "Dashboard(rubicon=rubicon).run_server_inline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dashboard](quick-look-dashboard.png \"dashboard\")\n",
    "\n",
    "By default, the dashboard launches on your localhost's port 8050. To view the dashboard inline in a notebook\n",
    "or in a new JupyterLab window, instantiate the ``Dashboard`` object with ``mode=\"inline\"`` or \n",
    "``mode=\"jupyterlab\"``, respectively.\n",
    "\n",
    "You don't even have to launch the dashboard from a Python interpreter. ``rubicon_ml`` comes packaged with a CLI that\n",
    "can launch the dashboard from your terminal.\n",
    "\n",
    "```\n",
    "rubicon_ml ui --root-dir ./rubicon-root\n",
    "```\n",
    "\n",
    "## Publishing & Sharing\n",
    "\n",
    "Once you have a project stored in S3, anyone with access to that bucket can use the Python library\n",
    "to pull down your project and explore the data themselves or they can visualize the project within the\n",
    "dashboard.\n",
    "\n",
    "Additionally, ``rubicon_ml`` offers a process to share a selected subset of your logged data via publishing and\n",
    "consuming custom [Intake](https://github.com/intake/intake) catalogs.\n",
    "\n",
    "### Publishing\n",
    "\n",
    "Here, we’ll publish some experiments by generating an Intake catalog. The catalog file, generated as YAML,\n",
    "simply points to the actual data and can be shared and versioned independently of your ``rubicon_ml`` project data.\n",
    "\n",
    "You can use the ``experiment_tags`` parameter to publish experiments with specific tags, like **success**.\n",
    "The resulting file will have a root ``sources`` key, followed by a number of sources representing experiments\n",
    "and/or projects. In this example, you'll notice the ``urlpaths`` are all local since we're using a local filesystem.\n",
    "Publishing is most useful when refrencing remote data in S3. That's because publishing does not change or move the\n",
    "data - it only references it's location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = rubicon.publish(\n",
    "    project.name,\n",
    "    experiment_tags=[\"success\"],\n",
    "    output_filepath=\"./wine_catalog.yml\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sources:\n",
      "  experiment_54d24e34_c0af_4565_909d_65b5900ba0e0:\n",
      "    args:\n",
      "      experiment_id: 54d24e34-c0af-4565-909d-65b5900ba0e0\n",
      "      project_name: Wine Classification\n",
      "      urlpath: /Users/ryan/oss/rubicon/notebooks/rubicon-root\n",
      "    driver: rubicon_ml_experiment\n"
     ]
    }
   ],
   "source": [
    "! head -7 wine_catalog.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consuming Published Projects & Experiments\n",
    "\n",
    "If you’ve been given a catalog of published experiments, you can easily load these with ``intake``\n",
    "and the custom ``rubicon_ml.intake_rubicon`` driver, which both come packaged with the Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake\n",
    "\n",
    "\n",
    "catalog = intake.open_catalog(\"./wine_catalog.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can use the ``catalog`` object to load the published projects or experiments into memory.\n",
    "From there, you'll have a ``rubicon_ml.Project`` or ``rubicon_ml.Experiment`` object you can use as you\n",
    "normally would!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<rubicon_ml.client.experiment.Experiment at 0x15f5437c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_source = catalog[list(catalog)[0]]\n",
    "\n",
    "first_source.discover()\n",
    "first_source.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this catalog doesn't point to any remote data, its not super useful.\n",
    "Let's clean up after ourselves and get rid of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm wine_catalog.yml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
